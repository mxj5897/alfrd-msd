{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Recognition\n",
    "### Using Python API  \n",
    "\n",
    "The dataset contains 14-20 photos of 2 individual. For privacy reasons, the dataset is not being uploaded to github. New users will need to create a dataset structured as below. The user should create directories for each potential end user. In each directory include at least 14-20 photos of the use.Each photo should contain no more than one face, which occupies the majority of the frame.\n",
    "\n",
    "The way the algorithm works is that each face is mapped to an embedding space prior to runtime. At runtime each new face is compared to the known faces using a standard nearest neighbor algorithm. For efficiency, only every nth incoming frame is processed.  \n",
    "\n",
    "**General Dataset Structure**  \n",
    "./Dataset  \n",
    "-->Mike  \n",
    "-->Bezankeng\n",
    "\n",
    "**Dependencies:**\n",
    "* face_recognition\n",
    "* cv2\n",
    "* numpy\n",
    "* csv\n",
    "* os\n",
    "\n",
    "### Embedding Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates embedding of facial recognition dataset\n",
    "def create_embedding(image):\n",
    "    load_image = face_recognition.load_image_file(image)\n",
    "    encoding = face_recognition.face_encodings(load_image)[0]\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loops through photos of a end user in a directory\n",
    "def load_folder(directory):\n",
    "    faces = list()\n",
    "    for filename in os.listdir(directory):\n",
    "        path = directory + filename\n",
    "        face = create_embedding(path)\n",
    "        faces.append(face)\n",
    "    return(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loops through all end users\n",
    "def load_dataset(directory):\n",
    "    x,y = list(), list()\n",
    "    \n",
    "    for subdir in os.listdir(directory):\n",
    "        path = directory + subdir + '/'\n",
    "\n",
    "        # skip files in directory\n",
    "        if not os.path.isdir(path):\n",
    "            continue\n",
    "        faces = load_folder(path)\n",
    "        labels = [subdir for _ in range(len(faces))]\n",
    "        \n",
    "        print('loaded %d examples from class: %s' %(len(faces),subdir))\n",
    "        \n",
    "        x.extend(faces)\n",
    "        y.extend(labels)\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create encodings for all the images in the dataset\n",
    "# Will take a few minutes to run, also will save out the encoding variables to csv files.\n",
    "# Only run this file if the existing csv files aren't available or need to be updated.\n",
    "encodings, names = load_dataset('dataset/')\n",
    "\n",
    "known_face_encodings = encodings\n",
    "known_face_names = names\n",
    "\n",
    "np.save('encodings', known_face_encodings)\n",
    "np.save('names', known_face_names)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in encodings and values. Faster alternative to reading in values manually\n",
    "# Need to have encodings.npy and names.npy in working directory\n",
    "known_face_encodings = np.load('encodings.npy')\n",
    "known_face_names = np.load('names.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # # If a match was found in known_face_encodings, just use the first one.\n",
    "            # if True in matches:\n",
    "            #     first_match_index = matches.index(True)\n",
    "            #     name = known_face_names[first_match_index]\n",
    "\n",
    "            # Or instead, use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            face_names.append(name)\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
